Trong bài lab 1 em đã được học các thuật toán:
- Autograd tự động tính đạo hàm. Pytorch tự động tính gradient bằng requires_grad=True.backward()
- Gradient Descent thủ công Lặp nhiều vòng: forward (tính y_hat) → loss → backward() → update w,b thủ công → zero_grad
- Linear Regression hồi quy tuyến tính
- MSE 
